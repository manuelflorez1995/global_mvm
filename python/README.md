# ğŸŒ Proyecto Global MVM

## ğŸ“‹ DescripciÃ³n
Este repositorio contiene los scripts y notebooks desarrollados como parte del **Reto de IngenierÃ­a de Datos + Cloud**, cuyo objetivo principal fue simular un flujo de datos empresarial mediante la generaciÃ³n y almacenamiento de informaciÃ³n estructurada.

En esta entrega se desarrollaron los **DesafÃ­os 1 y 2**, enfocados en la creaciÃ³n de datos sintÃ©ticos y su persistencia en formato CSV.

---

## ğŸ§© DesafÃ­os Desarrollados

### ğŸ”¹ DesafÃ­o 1: GeneraciÃ³n AutomÃ¡tica de Datos
Se construyÃ³ un script en Python que genera tres datasets relacionados:
- **Departamentos:** catÃ¡logo base con cÃ³digos y nombres.  
- **Puestos:** asociados a cada departamento, con rangos salariales.  
- **Empleados:** informaciÃ³n de 400 empleados simulados con relaciones coherentes entre las llaves forÃ¡neas.

Archivos generados:
| Archivo | DescripciÃ³n |
|----------|-------------|
| `departamento.csv` | Contiene los cÃ³digos y nombres de los departamentos. |
| `puestos.csv` | Define los puestos de trabajo y sus rangos salariales. |
| `empleados.csv` | Registra la informaciÃ³n de empleados, incluyendo departamento, puesto y salario. |

---

### ğŸ”¹ DesafÃ­o 2: Almacenamiento y Formato de Datos
Los datos generados se exportaron en formato **CSV**, con el propÃ³sito de garantizar su **portabilidad, legibilidad y compatibilidad** con diversas herramientas locales.  

No obstante, en escenarios de **Big Data** o procesamiento masivo de informaciÃ³n, se recomienda utilizar el formato **Parquet**, ya que ofrece **mayor eficiencia en almacenamiento, compresiÃ³n y velocidad de lectura** para volÃºmenes de datos de gran escala.

| Criterio | CSV | Parquet |
|-----------|-----|----------|
| **Facilidad de uso** | Alta: compatible con Excel, Power BI, bases SQL | Requiere librerÃ­as adicionales |
| **Peso y compresiÃ³n** | Mayor tamaÃ±o | Menor tamaÃ±o (compresiÃ³n columnar) |
| **Uso recomendado** | Procesos simples o cargas manuales | Procesos analÃ­ticos masivos o Data Lake |

---

## â˜ï¸ Arquitectura Referencial Propuesta
Aunque la implementaciÃ³n en la nube no se realizÃ³ por motivos de costo, se diseÃ±Ã³ una **arquitectura lÃ³gica en Azure** para una futura ampliaciÃ³n del proyecto:

**Flujo de datos:**
1. **Data Source (Flat files)** â†’ Archivos CSV generados localmente.  
2. **Azure Blob Storage** â†’ Capa de almacenamiento en la nube.  
3. **Azure Data Factory** â†’ OrquestaciÃ³n de procesos ETL.  
4. **Azure Database for PostgreSQL** â†’ Almacenamiento estructurado y consultas analÃ­ticas.  
5. **Power BI Service** â†’ Capa de consumo y visualizaciÃ³n.

*(Ver diagrama en la carpeta `docs/arquitectura.png` o imagen adjunta en el informe.)*

---

## âš™ï¸ TecnologÃ­as Utilizadas
| Componente | DescripciÃ³n |
|-------------|-------------|
| **Lenguaje** | Python 3.10 |
| **LibrerÃ­as** | pandas, numpy, faker |
| **Entorno** | Jupyter Notebook (`test_test.ipynb`) |
| **Formato de salida** | CSV (archivos planos) |
| **Arquitectura Cloud Referencial** | Azure Blob Storage + Data Factory + PostgreSQL + Power BI |

---

## ğŸ—‚ï¸ Estructura del Proyecto
global_mvm/
â”œâ”€ data/ # Archivos generados (CSV)
â”œâ”€ src/ # Scripts Python
â”‚ â”œâ”€ 01_generate_data.py
â”‚ â””â”€ 02_load_sqlite.py
â”œâ”€ notebooks/
â”‚ â””â”€ test_test.ipynb
â”œâ”€ docs/
â”‚ â””â”€ arquitectura.png
â””â”€ README.md